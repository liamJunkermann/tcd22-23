{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AHdY5Ws2UCf"
      },
      "source": [
        "# THE SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rBMQ39y919g9"
      },
      "outputs": [],
      "source": [
        "# import libs\n",
        "import time\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "if sys.version_info.major == 2:\n",
        "    import Tkinter as tk\n",
        "else:\n",
        "    import tkinter as tk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ATOYywuF2Bka"
      },
      "outputs": [],
      "source": [
        "# Variable Setup\n",
        "N_training = 20   # The number of training episodes\n",
        "\n",
        "decay_reward = 0.9  # Discount gamma for delayed reward\n",
        "\n",
        "learning_rate_inti = 0.5   # The initial value for learning rate\n",
        "epsilon_inti = 0.5         # The initial value for epsilon greedy\n",
        "decay_learning_rate = 0.9  # The decay factor for learning rate\n",
        "decay_epsilon = 0.9        # The decay factor for epsilon\n",
        "\n",
        "step_list = []            # The list recording steps used in each episode\n",
        "finished_episode_list = []  # record finished episode number for plot\n",
        "\n",
        "# the environment==================\n",
        "UNIT = 40   # pixels\n",
        "MAZE_H = 5  # grid height number\n",
        "MAZE_W = 5  # grid width number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R4g4Tr1O2IWD"
      },
      "outputs": [],
      "source": [
        "# The grid class object\n",
        "class Grid(tk.Tk, object):\n",
        "    def __init__(self):\n",
        "        super(Grid, self).__init__()\n",
        "        self.action_space = ['u', 'd', 'l', 'r']\n",
        "        self.n_actions = len(self.action_space)\n",
        "        self.title('Grid Trap')\n",
        "        self.geometry('{0}x{1}'.format(MAZE_H * UNIT, MAZE_H * UNIT))\n",
        "        self._build_maze()\n",
        "        self.terminate_reason = ' Our agent (Tï¼¿T) fel into a black hole'\n",
        "\n",
        "    def _build_maze(self):\n",
        "        self.canvas = tk.Canvas(self, bg='white',\n",
        "                                height=MAZE_H * UNIT,\n",
        "                                width=MAZE_W * UNIT)\n",
        "\n",
        "        # create grids\n",
        "        for c in range(0, MAZE_W * UNIT, UNIT):\n",
        "            x0, y0, x1, y1 = c, 0, c, MAZE_H * UNIT\n",
        "            self.canvas.create_line(x0, y0, x1, y1)\n",
        "        for r in range(0, MAZE_H * UNIT, UNIT):\n",
        "            x0, y0, x1, y1 = 0, r, MAZE_W * UNIT, r\n",
        "            self.canvas.create_line(x0, y0, x1, y1)\n",
        "\n",
        "        # create origin\n",
        "        origin = np.array([20, 20])\n",
        "\n",
        "        # hell\n",
        "        hell1_center = origin + np.array([UNIT * 3, UNIT])\n",
        "        self.hell1 = self.canvas.create_oval(\n",
        "            hell1_center[0] - 15, hell1_center[1] - 15,\n",
        "            hell1_center[0] + 15, hell1_center[1] + 15,\n",
        "            fill='black')\n",
        "        self.hell1_label = self.canvas.create_text(\n",
        "            (hell1_center[0], hell1_center[1]), text=\"-1\", fill='white', font='bold')\n",
        "        # hell\n",
        "        hell2_center = origin + np.array([UNIT*2, UNIT * 2])\n",
        "        self.hell2 = self.canvas.create_oval(\n",
        "            hell2_center[0] - 15, hell2_center[1] - 15,\n",
        "            hell2_center[0] + 15, hell2_center[1] + 15,\n",
        "            fill='black')\n",
        "        self.hell2_label = self.canvas.create_text(\n",
        "            (hell2_center[0], hell2_center[1]), text=\"-1\", fill='white', font='bold')\n",
        "\n",
        "        # create target\n",
        "        target_center = origin + np.array([UNIT*3, UNIT * 2])\n",
        "        self.oval = self.canvas.create_rectangle(\n",
        "            target_center[0] - 15, target_center[1] - 15,\n",
        "            target_center[0] + 15, target_center[1] + 15,\n",
        "            fill='red')\n",
        "        self.target_label = self.canvas.create_text(\n",
        "            (target_center[0], target_center[1]), text=\"+1\", fill='white', font='bold')\n",
        "        # create red rect\n",
        "        self.rect = self.canvas.create_rectangle(\n",
        "            origin[0] - 15, origin[1] - 15,\n",
        "            origin[0] + 15, origin[1] + 15,\n",
        "            fill='yellow')\n",
        "\n",
        "        # pack all\n",
        "        self.canvas.pack()\n",
        "\n",
        "    def reset(self):\n",
        "        self.update()\n",
        "        time.sleep(0.5)\n",
        "        self.canvas.delete(self.rect)\n",
        "        origin = np.array([20, 20])\n",
        "        self.terminate_reason = ' Our agent (T_T) fell into a black hole'\n",
        "        self.rect = self.canvas.create_rectangle(\n",
        "            origin[0] - 15, origin[1] - 15,\n",
        "            origin[0] + 15, origin[1] + 15,\n",
        "            fill='yellow')\n",
        "        # return observation\n",
        "        return self.canvas.coords(self.rect)\n",
        "\n",
        "    def step(self, action):\n",
        "        s = self.canvas.coords(self.rect)\n",
        "        base_action = np.array([0, 0])\n",
        "        if np.random.uniform() < 0.9:\n",
        "            # expected results if possible (not in border)\n",
        "            if action == 0:   # up\n",
        "                if s[1] > UNIT:\n",
        "                    base_action[1] -= UNIT\n",
        "            elif action == 1:   # down\n",
        "                if s[1] < (MAZE_H - 1) * UNIT:\n",
        "                    base_action[1] += UNIT\n",
        "            elif action == 3:   # right\n",
        "                if s[0] < (MAZE_W - 1) * UNIT:\n",
        "                    base_action[0] += UNIT\n",
        "            elif action == 2:   # left\n",
        "                if s[0] > UNIT:\n",
        "                    base_action[0] -= UNIT\n",
        "# random results with probability 0.1\n",
        "        else:\n",
        "            print(\"Randomized action\")\n",
        "            rc = np.random.choice(range(3))\n",
        "            if rc == 0:   # up\n",
        "                if s[1] > UNIT:\n",
        "                    base_action[1] -= UNIT\n",
        "            elif rc == 1:   # down\n",
        "                if s[1] < (MAZE_H - 1) * UNIT:\n",
        "                    base_action[1] += UNIT\n",
        "            elif rc == 3:   # right\n",
        "                if s[0] < (MAZE_W - 1) * UNIT:\n",
        "                    base_action[0] += UNIT\n",
        "            elif rc == 2:   # left\n",
        "                if s[0] > UNIT:\n",
        "                    base_action[0] -= UNIT\n",
        "\n",
        "        self.canvas.move(\n",
        "            self.rect, base_action[0], base_action[1])  # move agent\n",
        "\n",
        "        s_ = self.canvas.coords(self.rect)  # next state\n",
        "\n",
        "        # reward function\n",
        "        # the terminal state actually covers 3 states: the two black holes and the red target\n",
        "        if s_ == self.canvas.coords(self.oval):\n",
        "            reward = 1\n",
        "            done = True\n",
        "            self.terminate_reason = ' Our agent (>_<) won!'\n",
        "            s_ = 'terminal'\n",
        "\n",
        "        elif s_ in [self.canvas.coords(self.hell1), self.canvas.coords(self.hell2)]:\n",
        "            reward = -1\n",
        "            done = True\n",
        "            s_ = 'terminal'\n",
        "\n",
        "        else:\n",
        "            reward = 0\n",
        "            done = False\n",
        "\n",
        "        return s_, reward, done, self.terminate_reason\n",
        "\n",
        "    def render(self):\n",
        "        time.sleep(0.1)\n",
        "        self.update()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OQ45N7eR2Lyg"
      },
      "outputs": [],
      "source": [
        "class QLearningTable:\n",
        "    def __init__(self, actions, learning_rate, reward_decay, e_greedy):\n",
        "        self.actions = actions  # actions\n",
        "        self.lr = learning_rate\n",
        "        self.gamma = reward_decay\n",
        "        self.epsilon = e_greedy\n",
        "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
        "        self.step_count = 0  # record the steps in each episode before terminate\n",
        "        self.new_state_index = 1  # for print the row index\n",
        "\n",
        "    def choose_action(self, observation):\n",
        "        self.check_state_exist(observation)\n",
        "        # action selection\n",
        "        # print('real using epi:', self.epsilon)\n",
        "        if np.random.uniform() < (1 - self.epsilon):\n",
        "\n",
        "            # Q5.1 put your answer here; please take care about the indent\n",
        "            # B\n",
        "            state_action = self.q_table.loc[observation, :]\n",
        "            action = np.random.choice(\n",
        "                state_action[state_action == np.min(state_action)].index)\n",
        "        else:\n",
        "            # Q5.2 Put your answer here; please take care about the indent\n",
        "            # E\n",
        "            action = np.random.choice(self.actions)\n",
        "\n",
        "        return action\n",
        "# ===================================================\n",
        "        \"\"\"        \n",
        "            # Choose your answer for Q5 from below (to complete the code).\n",
        "        A):\n",
        "            action = self.q_table.loc[observation, :]\n",
        "\n",
        "        B):\n",
        "            state_action = self.q_table.loc[observation, :]\n",
        "            action = np.random.choice(state_action[state_action == np.max(state_action)].index)\n",
        "\n",
        "        C):\n",
        "            state_action = self.q_table.loc[observation, :]\n",
        "            action = np.random.choice(state_action[state_action == np.min(state_action)].index)\n",
        "\n",
        "        D):\n",
        "            action = self.q_table.loc[observation, 2]\n",
        "\n",
        "        E):\n",
        "            action = np.random.choice(self.actions)\n",
        "            \"\"\"\n",
        "# ====================================================================================================\n",
        "\n",
        "    def learn(self, s, a, r, s_):\n",
        "        self.check_state_exist(s_)\n",
        "        q_predict = self.q_table.loc[s, a]\n",
        "        self.step_count += 1\n",
        "        if s_ != 'terminal':\n",
        "            # next state is not terminal\n",
        "            q_target = r + self.gamma * self.q_table.loc[s_, :].max()\n",
        "        else:\n",
        "            q_target = r  # next state is terminal\n",
        "        self.q_table.loc[s, a] += self.lr * (q_target - q_predict)  # update\n",
        "        # print('real using lr:',self.lr)\n",
        "        return self.q_table, self.step_count\n",
        "\n",
        "    def set_lr(self, decay):\n",
        "        if self.lr > 0.00001:\n",
        "            self.lr = decay * self.lr\n",
        "        else:\n",
        "            print('Learning rate is small enough and close to 0.')\n",
        "        return self.lr\n",
        "\n",
        "    def set_epsilon(self, decay):\n",
        "        if self.epsilon > 0.00001:\n",
        "            self.epsilon = decay * self.epsilon\n",
        "        else:\n",
        "            print('epsilon is small enough and close to 0.')\n",
        "        return self.epsilon\n",
        "\n",
        "    def check_state_exist(self, state):\n",
        "        if state not in self.q_table.index:\n",
        "            # append new state to q table\n",
        "            new_state_name = 'S' + str(self.new_state_index)\n",
        "            print('Add a new state', new_state_name, ' into the Q table')\n",
        "            self.new_state_index += 1\n",
        "            self.q_table = self.q_table.append(\n",
        "                pd.Series(\n",
        "                    [0]*len(self.actions),\n",
        "                    index=self.q_table.columns,\n",
        "                    name=state,\n",
        "                )\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "O_zXAx832Pzz"
      },
      "outputs": [],
      "source": [
        "def update():\n",
        "    for episode in range(N_training):\n",
        "        if episode == 0:\n",
        "            print('Learning rate for episode {} is:'.format(\n",
        "                episode), learning_rate_inti)\n",
        "            print('Epsilon for episode {} is:'.format(episode), epsilon_inti)\n",
        "        else:\n",
        "            new_lr = RL.set_lr(decay_learning_rate)  # set decay learning rate\n",
        "            print('Learning rate for episode {} is:'.format(episode), new_lr)\n",
        "            new_epsilon = RL.set_epsilon(decay_epsilon)  # set decay epsilon\n",
        "            print('Epsilon for episode {} is:'.format(episode), new_epsilon)\n",
        "\n",
        "        # initial observation\n",
        "        observation = env.reset()  # reset environment\n",
        "\n",
        "        while True:\n",
        "            # fresh env\n",
        "            env.render()\n",
        "\n",
        "            print(\"State before action:\", decodeXY(observation))\n",
        "\n",
        "            # RL choose action based on observation\n",
        "            action = RL.choose_action(str(observation))\n",
        "\n",
        "            print(\" action chosen:\", decodeAct(action))\n",
        "\n",
        "            # RL take action and get next observation and reward\n",
        "            observation_, reward, done, reason = env.step(action)\n",
        "\n",
        "            # RL learn from this transition\n",
        "            RL.learn(str(observation), action, reward, str(observation_))\n",
        "\n",
        "            # swap observation\n",
        "            observation = observation_\n",
        "\n",
        "            # break while loop when end of this episode\n",
        "            if done:\n",
        "                print('Episode {} finished.{} and used {} steps'.format(\n",
        "                    episode, reason, RL.step_count))\n",
        "                finished_episode_list.append(episode)\n",
        "                if reason == ' Our agent (>_<) won!':\n",
        "                    step_list.append(RL.step_count)\n",
        "                else:\n",
        "                    step_list.append(None)\n",
        "                RL.step_count = 0\n",
        "                print('=======================================================')\n",
        "                break\n",
        "\n",
        "    # end of game\n",
        "    print('Training Over')\n",
        "    env.destroy()\n",
        "\n",
        "\n",
        "def decodeXY(a):\n",
        "    x = (a[0]-5)/40 + 1\n",
        "    y = (a[1]-5)/40 + 1\n",
        "    return ('row,column =' + str(int(y)) + ',' + str(int(x)))\n",
        "\n",
        "\n",
        "def decodeAct(x):\n",
        "    if x == 0:\n",
        "        return ('u')\n",
        "    elif x == 1:\n",
        "        return ('d')\n",
        "    elif x == 2:\n",
        "        return ('l')\n",
        "    elif x == 3:\n",
        "        return ('r')\n",
        "\n",
        "\n",
        "def indexXY(arStrng):\n",
        "    temp = []\n",
        "    for strng in arStrng:\n",
        "        temp.append(decXY(strng))\n",
        "    return (temp)\n",
        "\n",
        "\n",
        "def decXY(strng):\n",
        "    if strng == 'terminal':\n",
        "        return strng\n",
        "    else:\n",
        "        comma = strng.index(',')\n",
        "        a = strng[1:comma]\n",
        "        if a == \"5.0\":\n",
        "            x = 1\n",
        "        elif a == \"45.0\":\n",
        "            x = 2\n",
        "        elif a == \"85.0\":\n",
        "            x = 3\n",
        "        elif a == \"125.0\":\n",
        "            x = 4\n",
        "        elif a == \"165.0\":\n",
        "            x = 5\n",
        "        if strng[comma+2:comma+5] == \"5.0\":\n",
        "            y = 1\n",
        "        elif strng[comma+2:comma+6] == \"45.0\":\n",
        "            y = 2\n",
        "        elif strng[comma+2:comma+6] == \"85.0\":\n",
        "            y = 3\n",
        "        elif strng[comma+2:comma+7] == \"125.0\":\n",
        "            y = 4\n",
        "        elif strng[comma+2:comma+7] == \"165.0\":\n",
        "            y = 5\n",
        "        return ('row,column =' + str(y) + ',' + str(x))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV6Kq1hL2XuZ"
      },
      "source": [
        "# The Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "Mr7NuSf22ZSg",
        "outputId": "f4b9b94f-3a5f-49c0-8526-1a9eb837908e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Learning rate for episode 0 is: 0.5\n",
            "Epsilon for episode 0 is: 0.5\n",
            "State before action: row,column =1,1\n",
            "Add a new state S1  into the Q table\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "Add a new state S2  into the Q table\n",
            "State before action: row,column =1,2\n",
            " action chosen: r\n",
            "Add a new state S3  into the Q table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n",
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =1,3\n",
            " action chosen: d\n",
            "Add a new state S4  into the Q table\n",
            "State before action: row,column =2,3\n",
            " action chosen: r\n",
            "Add a new state S5  into the Q table\n",
            "Episode 0 finished. Our agent (T_T) fell into a black hole and used 6 steps\n",
            "=======================================================\n",
            "Learning rate for episode 1 is: 0.45\n",
            "Epsilon for episode 1 is: 0.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n",
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: r\n",
            "Randomized action\n",
            "State before action: row,column =1,2\n",
            " action chosen: d\n",
            "Add a new state S6  into the Q table\n",
            "State before action: row,column =2,2\n",
            " action chosen: d\n",
            "Add a new state S7  into the Q table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n",
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =3,2\n",
            " action chosen: l\n",
            "Add a new state S8  into the Q table\n",
            "State before action: row,column =3,1\n",
            " action chosen: r\n",
            "Randomized action\n",
            "Add a new state S9  into the Q table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n",
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =4,1\n",
            " action chosen: l\n",
            "State before action: row,column =4,1\n",
            " action chosen: u\n",
            "State before action: row,column =3,1\n",
            " action chosen: d\n",
            "State before action: row,column =4,1\n",
            " action chosen: l\n",
            "State before action: row,column =4,1\n",
            " action chosen: r\n",
            "Add a new state S10  into the Q table\n",
            "State before action: row,column =4,2\n",
            " action chosen: d\n",
            "Add a new state S11  into the Q table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n",
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =5,2\n",
            " action chosen: d\n",
            "State before action: row,column =5,2\n",
            " action chosen: d\n",
            "State before action: row,column =5,2\n",
            " action chosen: u\n",
            "State before action: row,column =4,2\n",
            " action chosen: l\n",
            "Randomized action\n",
            "State before action: row,column =4,1\n",
            " action chosen: u\n",
            "State before action: row,column =3,1\n",
            " action chosen: u\n",
            "Add a new state S12  into the Q table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =2,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: r\n",
            "State before action: row,column =1,3\n",
            " action chosen: u\n",
            "Randomized action\n",
            "State before action: row,column =1,2\n",
            " action chosen: d\n",
            "State before action: row,column =2,2\n",
            " action chosen: l\n",
            "State before action: row,column =2,1\n",
            " action chosen: r\n",
            "State before action: row,column =2,2\n",
            " action chosen: d\n",
            "State before action: row,column =3,2\n",
            " action chosen: l\n",
            "State before action: row,column =3,1\n",
            " action chosen: u\n",
            "State before action: row,column =2,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: d\n",
            "State before action: row,column =2,2\n",
            " action chosen: d\n",
            "State before action: row,column =3,2\n",
            " action chosen: l\n",
            "State before action: row,column =3,1\n",
            " action chosen: u\n",
            "State before action: row,column =2,1\n",
            " action chosen: d\n",
            "State before action: row,column =3,1\n",
            " action chosen: l\n",
            "State before action: row,column =3,1\n",
            " action chosen: l\n",
            "State before action: row,column =3,1\n",
            " action chosen: l\n",
            "State before action: row,column =3,1\n",
            " action chosen: d\n",
            "State before action: row,column =4,1\n",
            " action chosen: d\n",
            "Add a new state S13  into the Q table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =5,1\n",
            " action chosen: d\n",
            "Randomized action\n",
            "State before action: row,column =5,1\n",
            " action chosen: l\n",
            "State before action: row,column =5,1\n",
            " action chosen: u\n",
            "State before action: row,column =4,1\n",
            " action chosen: l\n",
            "State before action: row,column =4,1\n",
            " action chosen: l\n",
            "State before action: row,column =4,1\n",
            " action chosen: r\n",
            "State before action: row,column =4,2\n",
            " action chosen: u\n",
            "State before action: row,column =3,2\n",
            " action chosen: l\n",
            "State before action: row,column =3,1\n",
            " action chosen: l\n",
            "State before action: row,column =3,1\n",
            " action chosen: d\n",
            "State before action: row,column =4,1\n",
            " action chosen: d\n",
            "State before action: row,column =5,1\n",
            " action chosen: d\n",
            "State before action: row,column =5,1\n",
            " action chosen: d\n",
            "State before action: row,column =5,1\n",
            " action chosen: r\n",
            "State before action: row,column =5,2\n",
            " action chosen: r\n",
            "Add a new state S14  into the Q table\n",
            "State before action: row,column =5,3\n",
            " action chosen: u\n",
            "Add a new state S15  into the Q table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n",
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =4,3\n",
            " action chosen: d\n",
            "State before action: row,column =5,3\n",
            " action chosen: d\n",
            "State before action: row,column =5,3\n",
            " action chosen: u\n",
            "State before action: row,column =4,3\n",
            " action chosen: r\n",
            "Randomized action\n",
            "Episode 1 finished. Our agent (T_T) fell into a black hole and used 68 steps\n",
            "=======================================================\n",
            "Learning rate for episode 2 is: 0.405\n",
            "Epsilon for episode 2 is: 0.405\n",
            "State before action: row,column =1,1\n",
            " action chosen: d\n",
            "State before action: row,column =2,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: r\n",
            "State before action: row,column =1,3\n",
            " action chosen: l\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: u\n",
            "State before action: row,column =1,2\n",
            " action chosen: r\n",
            "State before action: row,column =1,3\n",
            " action chosen: u\n",
            "State before action: row,column =1,3\n",
            " action chosen: l\n",
            "State before action: row,column =1,2\n",
            " action chosen: u\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: r\n",
            "State before action: row,column =1,3\n",
            " action chosen: l\n",
            "State before action: row,column =1,2\n",
            " action chosen: u\n",
            "State before action: row,column =1,2\n",
            " action chosen: u\n",
            "State before action: row,column =1,2\n",
            " action chosen: d\n",
            "State before action: row,column =2,2\n",
            " action chosen: d\n",
            "Randomized action\n",
            "State before action: row,column =1,2\n",
            " action chosen: d\n",
            "State before action: row,column =2,2\n",
            " action chosen: u\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: u\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n",
            "Randomized action\n",
            "State before action: row,column =1,1\n",
            " action chosen: d\n",
            "Randomized action\n",
            "State before action: row,column =2,1\n",
            " action chosen: l\n",
            "State before action: row,column =2,1\n",
            " action chosen: r\n",
            "State before action: row,column =2,2\n",
            " action chosen: l\n",
            "State before action: row,column =2,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: d\n",
            "Randomized action\n",
            "State before action: row,column =2,1\n",
            " action chosen: r\n",
            "State before action: row,column =2,2\n",
            " action chosen: l\n",
            "State before action: row,column =2,1\n",
            " action chosen: l\n",
            "State before action: row,column =2,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: u\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: r\n",
            "State before action: row,column =1,3\n",
            " action chosen: l\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: d\n",
            "State before action: row,column =2,1\n",
            " action chosen: r\n",
            "State before action: row,column =2,2\n",
            " action chosen: u\n",
            "State before action: row,column =1,2\n",
            " action chosen: d\n",
            "Randomized action\n",
            "State before action: row,column =1,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n",
            "Randomized action\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: u\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: d\n",
            "State before action: row,column =2,1\n",
            " action chosen: l\n",
            "State before action: row,column =2,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: d\n",
            "State before action: row,column =2,1\n",
            " action chosen: d\n",
            "State before action: row,column =3,1\n",
            " action chosen: u\n",
            "State before action: row,column =2,1\n",
            " action chosen: d\n",
            "State before action: row,column =3,1\n",
            " action chosen: l\n",
            "State before action: row,column =3,1\n",
            " action chosen: u\n",
            "State before action: row,column =2,1\n",
            " action chosen: r\n",
            "State before action: row,column =2,2\n",
            " action chosen: l\n",
            "State before action: row,column =2,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: d\n",
            "State before action: row,column =2,1\n",
            " action chosen: d\n",
            "Randomized action\n",
            "State before action: row,column =1,1\n",
            " action chosen: d\n",
            "State before action: row,column =2,1\n",
            " action chosen: l\n",
            "State before action: row,column =2,1\n",
            " action chosen: d\n",
            "State before action: row,column =3,1\n",
            " action chosen: d\n",
            "State before action: row,column =4,1\n",
            " action chosen: l\n",
            "State before action: row,column =4,1\n",
            " action chosen: d\n",
            "State before action: row,column =5,1\n",
            " action chosen: u\n",
            "State before action: row,column =4,1\n",
            " action chosen: r\n",
            "State before action: row,column =4,2\n",
            " action chosen: l\n",
            "State before action: row,column =4,1\n",
            " action chosen: r\n",
            "State before action: row,column =4,2\n",
            " action chosen: r\n",
            "State before action: row,column =4,3\n",
            " action chosen: r\n",
            "Add a new state S16  into the Q table\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n",
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n",
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =4,4\n",
            " action chosen: d\n",
            "Add a new state S17  into the Q table\n",
            "State before action: row,column =5,4\n",
            " action chosen: r\n",
            "Add a new state S18  into the Q table\n",
            "State before action: row,column =5,5\n",
            " action chosen: u\n",
            "Add a new state S19  into the Q table\n",
            "State before action: row,column =4,5\n",
            " action chosen: l\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3x/7qtdp9gd4t96285blt4dfmnc0000gp/T/ipykernel_87123/1551500960.py:83: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  self.q_table = self.q_table.append(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State before action: row,column =4,4\n",
            " action chosen: d\n",
            "State before action: row,column =5,4\n",
            " action chosen: u\n",
            "State before action: row,column =4,4\n",
            " action chosen: u\n",
            "Episode 2 finished. Our agent (>_<) won! and used 92 steps\n",
            "=======================================================\n",
            "Learning rate for episode 3 is: 0.36450000000000005\n",
            "Epsilon for episode 3 is: 0.36450000000000005\n",
            "State before action: row,column =1,1\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: r\n",
            "State before action: row,column =1,3\n",
            " action chosen: d\n",
            "State before action: row,column =2,3\n",
            " action chosen: r\n",
            "Episode 3 finished. Our agent (T_T) fell into a black hole and used 5 steps\n",
            "=======================================================\n",
            "Learning rate for episode 4 is: 0.32805000000000006\n",
            "Epsilon for episode 4 is: 0.32805000000000006\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: l\n",
            "State before action: row,column =1,1\n",
            " action chosen: u\n",
            "State before action: row,column =1,1\n",
            " action chosen: r\n",
            "State before action: row,column =1,2\n",
            " action chosen: d\n",
            "State before action: row,column =2,2\n",
            " action chosen: r\n",
            "State before action: row,column =2,3\n",
            " action chosen: r\n",
            "Episode 4 finished. Our agent (T_T) fell into a black hole and used 7 steps\n",
            "=======================================================\n",
            "Training Over\n",
            "Q table:\n",
            "                     u    d    l         r\n",
            "row,column =1,1  0.000  0.0  0.0  0.000000\n",
            "row,column =1,2  0.000  0.0  0.0  0.000000\n",
            "row,column =1,3  0.000  0.0  0.0  0.000000\n",
            "row,column =2,3  0.000  0.0  0.0 -0.786488\n",
            "terminal         0.000  0.0  0.0  0.000000\n",
            "row,column =2,2  0.000  0.0  0.0  0.000000\n",
            "row,column =3,2  0.000  0.0  0.0  0.000000\n",
            "row,column =3,1  0.000  0.0  0.0  0.000000\n",
            "row,column =4,1  0.000  0.0  0.0  0.000000\n",
            "row,column =4,2  0.000  0.0  0.0  0.000000\n",
            "row,column =5,2  0.000  0.0  0.0  0.000000\n",
            "row,column =2,1  0.000  0.0  0.0  0.000000\n",
            "row,column =5,1  0.000  0.0  0.0  0.000000\n",
            "row,column =5,3  0.000  0.0  0.0  0.000000\n",
            "row,column =4,3  0.000  0.0  0.0 -0.267750\n",
            "row,column =4,4  0.405  0.0  0.0  0.000000\n",
            "row,column =5,4  0.000  0.0  0.0  0.000000\n",
            "row,column =5,5  0.000  0.0  0.0  0.000000\n",
            "row,column =4,5  0.000  0.0  0.0  0.000000\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "env = Grid()\n",
        "RL = QLearningTable(actions=list(range(env.n_actions)), learning_rate=learning_rate_inti,\n",
        "                    reward_decay=decay_reward, e_greedy=epsilon_inti)   # This describes the training\n",
        "env.after(100, update)\n",
        "env.mainloop()\n",
        "# output our training result\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "q_table = RL.q_table.rename(columns={0: 'u', 1: 'd', 2: 'l', 3: 'r'})\n",
        "q_table.index = indexXY(q_table.index)\n",
        "print('Q table:')\n",
        "print(q_table)\n",
        "plt.plot(finished_episode_list, step_list, 'bo-')\n",
        "plt.title('Steps needed for win')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Steps used in one Episode')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.16 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "375ad2bf1b16fc37fa5b03527ce14bff260e63861a5395507c42591b94e8e6bd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
